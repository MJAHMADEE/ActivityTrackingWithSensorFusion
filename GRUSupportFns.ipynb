{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "import math\n",
    "import sys\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "import numba\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.utils import shuffle\n",
    "from IPython.display import display, HTML\n",
    "%run KalmanFilter.ipynb\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K \n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.keras.initializers import RandomUniform\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 11\n",
    "y_dim = 2\n",
    "def create_input_and_output(data, just_acc=False):\n",
    "    ## Needed Data\n",
    "    gps = data.gps[:,1:3] \n",
    "    acc = data.acc_ERC[:, 1:4]\n",
    "    mag = data.mag[:, 1:3]\n",
    "    gyro = data.gyro[:, 1:4]\n",
    "\n",
    "    time_series = data.acc_ERC[:, 0]\n",
    "    ground_truth = data.ground_truth.dis[:, 1:3]\n",
    "    delta_time = np.diff(time_series, axis=0)\n",
    "    delta_time = np.concatenate(([[0]], delta_time))\n",
    "\n",
    "    # Choose which data to include in input\n",
    "    if (just_acc):\n",
    "        input_data = np.concatenate((gps, acc, delta_time), axis=1)\n",
    "    else:\n",
    "        input_data = np.concatenate((gps, acc, gyro, mag, delta_time), axis=1) ## Feature Vector Length = 11\n",
    "    return input_data, ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(filename, train_percentage=0.8):\n",
    "    #Load Data File\n",
    "    data = Data_Stream(filename, load_truth=True)\n",
    "    \n",
    "    #Create input and ouput data\n",
    "    input_data, ground_truth = create_input_and_output(data)\n",
    "    \n",
    "    x_dim = input_data.shape[1]\n",
    "    y_dim = ground_truth.shape[1]\n",
    "\n",
    "    num_train = int(train_percentage*len(input_data))\n",
    "    num_test = len(input_data) - num_train\n",
    "\n",
    "    training_data   = input_data[:num_train, :]\n",
    "    training_labels = ground_truth[:num_train, :]\n",
    "\n",
    "    test_data     = input_data[num_train:, :]\n",
    "    test_labels   = ground_truth[num_train:, :]\n",
    "    \n",
    "    return training_data, training_labels, test_data, test_labels, data.gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3000.  3000.  3000.  3000.  3000.  3000.  3000.  3000.  3000.  3000.\n",
      "   3000.]\n",
      " [-3000. -3000. -3000. -3000. -3000. -3000. -3000. -3000. -3000. -3000.\n",
      "  -3000.]]\n"
     ]
    }
   ],
   "source": [
    "gps_bound = 3000.0\n",
    "acc_bound = 3000.0 #Actual bound (30)\n",
    "gyro_bound = 3000.0 #Actual bound (2)\n",
    "mag_bound = 3000.0 #Actual bound (30)\n",
    "dt_bound = 3000.0 #Actual bound (0.1)\n",
    "\n",
    "custom_scale_matrix = np.asmatrix([gps_bound, gps_bound,\n",
    "                                   acc_bound, acc_bound, acc_bound, \n",
    "                                   gyro_bound, gyro_bound, gyro_bound,\n",
    "                                   mag_bound, mag_bound, dt_bound])\n",
    "custom_scale_matrix = np.concatenate((custom_scale_matrix, -custom_scale_matrix))\n",
    "\n",
    "print(custom_scale_matrix)\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scaler = x_scaler.fit(custom_scale_matrix)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler = y_scaler.fit(custom_scale_matrix[:, 0:2])\n",
    "\n",
    "def scale_data(training_data, training_labels, test_data, test_labels):\n",
    "\n",
    "    norm_training_data = x_scaler.transform(training_data)\n",
    "    norm_test_data = x_scaler.transform(test_data)\n",
    "    norm_training_labels = y_scaler.transform(training_labels)\n",
    "    norm_test_labels = y_scaler.transform(test_labels)\n",
    "    \n",
    "    \n",
    "    return norm_training_data, norm_training_labels, norm_test_data, norm_test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    \n",
    "\n",
    "    x_seqs = []\n",
    "    y_seqs = []\n",
    "    \n",
    "    ##Create all sequences\n",
    "    for i in range(0, len(norm_training_data) - sequence_length, 1):\n",
    "        x_seqs.append(norm_training_data[i:i+sequence_length])\n",
    "        y_seqs.append(norm_training_labels[i:i+sequence_length])\n",
    "    x_seqs = np.asarray(x_seqs)\n",
    "    y_seqs = np.asarray(y_seqs)\n",
    "    \n",
    "    print(x_seqs.shape)\n",
    "    \n",
    "    x_seqs, y_seqs = shuffle(x_seqs, y_seqs)\n",
    "    #Print number of batches required to pass all sequences in an epoch\n",
    "    print(\"Batches per Epoch: \", int(len(x_seqs)/batch_size + 1))\n",
    "    while True:\n",
    "        \n",
    "        #For each batch in an epoch, given n sequences that are in shuffled order\n",
    "        for i in range(int(len(x_seqs)/batch_size + 1)):\n",
    "            i1 = i+1\n",
    "            yield (x_seqs[i*batch_size:i1*batch_size], y_seqs[i*batch_size:i1*batch_size])\n",
    "        #Shuffle sequences between epochs\n",
    "        x_seqs, y_seqs = shuffle(x_seqs, y_seqs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed File\n",
      "Freq. of Acceleration 1583.554443181799\n",
      "Freq. of Lin. Acceleration 669.8833983859098\n",
      "Freq. of Gyroscope 1585.3892195648934\n",
      "Interpolated Samples\n",
      "Loaded Ground Truth\n",
      "Rotated Acceleration\n",
      "Integrated Acceleration\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels, test_data, test_labels,_ = load_train_test_data('uni.csv', 0.8)\n",
    "\n",
    "norm_training_data, norm_training_labels, norm_test_data, norm_test_labels = scale_data(training_data, training_labels, \n",
    "                                                                                        test_data, test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=512, sequence_length=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81292, 100, 11)\n",
      "Batches per Epoch:  159\n",
      "[[[0.42468934 0.50880333 0.49972448 ... 0.50595104 0.49670768 0.50000126]\n",
      "  [0.42468617 0.5088037  0.49975084 ... 0.50586017 0.49673633 0.50000084]\n",
      "  [0.42468301 0.50880407 0.49977411 ... 0.50586104 0.49670724 0.50000084]\n",
      "  ...\n",
      "  [0.42430896 0.50884808 0.50004287 ... 0.506232   0.49753317 0.50000084]\n",
      "  [0.4243058  0.50884845 0.50006471 ... 0.50623179 0.49756201 0.50000084]\n",
      "  [0.42430263 0.50884882 0.50008957 ... 0.50623158 0.49759091 0.50000084]]\n",
      "\n",
      " [[0.48725649 0.50055255 0.50015923 ... 0.50487082 0.49613044 0.50000042]\n",
      "  [0.48725244 0.50055185 0.50016075 ... 0.50478018 0.49621682 0.50000126]\n",
      "  [0.48724975 0.50055138 0.50015479 ... 0.50471983 0.49627433 0.50000084]\n",
      "  ...\n",
      "  [0.48696254 0.50050187 0.50026988 ... 0.50487628 0.49646592 0.50000042]\n",
      "  [0.48695984 0.5005014  0.50026748 ... 0.50493583 0.4964374  0.50000084]\n",
      "  [0.4869517  0.5005     0.50025152 ... 0.5047513  0.49626426 0.50000252]]\n",
      "\n",
      " [[0.37427893 0.51481007 0.49995291 ... 0.50457216 0.50278968 0.50000084]\n",
      "  [0.3742779  0.51481138 0.49996051 ... 0.50454325 0.50293434 0.50000084]\n",
      "  [0.37427687 0.51481268 0.49998118 ... 0.50455939 0.50300577 0.50000084]\n",
      "  ...\n",
      "  [0.37419189 0.51496497 0.50025589 ... 0.50417053 0.50319082 0.50000042]\n",
      "  [0.37419134 0.51496706 0.50019477 ... 0.50430445 0.5030764  0.50000126]\n",
      "  [0.37419097 0.51496845 0.50013777 ... 0.50427446 0.50307619 0.50000084]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.40467965 0.50681087 0.49898183 ... 0.50381267 0.5043455  0.50000084]\n",
      "  [0.40467722 0.50681068 0.49899091 ... 0.50378294 0.50434525 0.50000084]\n",
      "  [0.4046748  0.50681049 0.49905762 ... 0.50375333 0.504345   0.50000084]\n",
      "  ...\n",
      "  [0.40436748 0.50686857 0.50076255 ... 0.50153668 0.50597055 0.50000378]\n",
      "  [0.40436612 0.50686886 0.5008248  ... 0.50156641 0.50598536 0.50000042]\n",
      "  [0.40436342 0.50686941 0.50091404 ... 0.50162527 0.50601469 0.50000084]]\n",
      "\n",
      " [[0.34665034 0.5336554  0.49975599 ... 0.50427935 0.50425873 0.50000084]\n",
      "  [0.34664885 0.5336567  0.4997477  ... 0.50421465 0.50418002 0.50000084]\n",
      "  [0.34664737 0.533658   0.49973621 ... 0.50422646 0.50406915 0.50000084]\n",
      "  ...\n",
      "  [0.34649525 0.5337952  0.49980702 ... 0.50290717 0.50555483 0.50000084]\n",
      "  [0.34649312 0.53379719 0.49984846 ... 0.50286369 0.50572773 0.50000126]\n",
      "  [0.34649171 0.53379851 0.49985049 ... 0.50286507 0.50581366 0.50000084]]\n",
      "\n",
      " [[0.41667938 0.51048922 0.50000079 ... 0.50349374 0.49934595 0.50000084]\n",
      "  [0.41667952 0.51048927 0.50000185 ... 0.5035088  0.49940321 0.50000042]\n",
      "  [0.41667994 0.51048941 0.50000982 ... 0.5035544  0.49957661 0.50000126]\n",
      "  ...\n",
      "  [0.4167116  0.51049996 0.50002595 ... 0.50381224 0.49974365 0.50000042]\n",
      "  [0.41671202 0.5105001  0.50002036 ... 0.5037672  0.49983016 0.50000126]\n",
      "  [0.4167123  0.51050019 0.50001643 ... 0.50373722 0.49988775 0.50000084]]]\n",
      "(512, 100, 11)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "batches = []\n",
    "batches.append(next(generator))\n",
    "print(batches[-1][0])\n",
    "for i in range(159):\n",
    "    batches.append(next(generator))\n",
    "print(batches[-1][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "    \n",
    "    \n",
    "#     ts = tf.reshape(y_true_slice, (-1, 2))\n",
    "    \n",
    "#     ps = tf.reshape(y_pred_slice, (-1, 2))\n",
    "    \n",
    "#     def get_min_dist(pi):\n",
    "# #         print(pi.get_shape(), ts.get_shape())\n",
    "#         eu_dists = tf.norm(ts-pi, ord='euclidean', axis=1)\n",
    "#         min_dist = tf.reduce_min(eu_dists)\n",
    "#         return min_dist\n",
    "\n",
    "\n",
    "#     min_dists = tf.map_fn(get_min_dist, ps, dtype=tf.float32)\n",
    "#     print(\"Minimum distances to Ground Truth Points Shape\", min_dists.get_shape())\n",
    "#     mean_dist = tf.reduce_mean(min_dists)\n",
    "#     print(\"Mean Mimimum Distance Shape\", mean_dist.get_shape())\n",
    "    \n",
    "# #     min_dists_tot = 0.0\n",
    "# #     print(ps.shape)\n",
    "# #     for pi in ps:\n",
    "# #         min_t = sys.float_info.max\n",
    "# #         for ti in ts:\n",
    "# #             t = tf.norm(ti-pi, ord='euclidean')\n",
    "# #             if(t < min_t):\n",
    "# #                 min_t = t\n",
    "# #         min_dists_tot += min_t\n",
    "        \n",
    "# #     mean_dist = min_dists_tot/len(ps)\n",
    "    \n",
    "    eu_dists = tf.norm(y_true_slice-y_pred_slice, ord='euclidean')\n",
    "    loss_mean = tf.reduce_mean(eu_dists)\n",
    "    \n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.ioff()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(filename, start_index=0, individual_signals=False, train_percentage=0.8, seq_len=100):\n",
    "    training_data, training_labels, test_data, test_labels, orig_gps = load_train_test_data(filename, train_percentage)\n",
    "\n",
    "    \n",
    "    trial_input = np.concatenate((training_data, test_data))\n",
    "    ground_truth = np.concatenate((training_labels, test_labels))\n",
    "    \n",
    "    #Pad input\n",
    "    padding = np.zeros((seq_len, training_data.shape[1]))\n",
    "    trial_input = np.concatenate((padding,trial_input))\n",
    "\n",
    "    ##Scale down the trial input, get predicted output\n",
    "    trial_input = x_scaler.transform(trial_input)\n",
    "    trial_input = np.expand_dims(trial_input, axis=0)\n",
    "    predicted_output = model.predict(trial_input)\n",
    "    \n",
    "    \n",
    "    ## Remove data upto the start point\n",
    "    ground_truth = ground_truth[start_index:]\n",
    "    orig_gps = orig_gps[start_index:]\n",
    "    predicted_output = y_scaler.inverse_transform(predicted_output[0])[start_index+seq_len:]\n",
    "    \n",
    "\n",
    "    # The output of the model is between 0 and 1. Inverse rescale to get input\n",
    "    if(individual_signals):\n",
    "        for signal in range(ground_truth_output.shape[1]):\n",
    "\n",
    "            # Make the plotting-canvas bigger.\n",
    "            plt.figure(figsize=(8,5))\n",
    "\n",
    "            # Plot and compare the ground truth and Model predicted versions\n",
    "            plt.plot(ground_truth[:, signal],'ro', label='true')\n",
    "            plt.plot(predicted_output[:, signal], label='pred')\n",
    "\n",
    "            # Plot grey box for warmup-period.\n",
    "            p = plt.axvspan(0, warmup_steps, facecolor='red', alpha=0.15)\n",
    "\n",
    "            # Plot labels etc.\n",
    "            plt.ylabel(\"X Displacement\" if signal == 0 else \"Y Displacement\")\n",
    "            plt.xlabel(\"Timestep\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "    ##Print Graphs of X against Y\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(ground_truth[:, 0], ground_truth[:, 1], label='ground truth', color = 'g')\n",
    "    plt.plot(predicted_output[:len(training_data), 0], predicted_output[:len(training_data), 1], \n",
    "             label='seen training data', color = 'b')\n",
    "    plt.plot(predicted_output[len(training_data):, 0], predicted_output[len(training_data):, 1], \n",
    "             label='unseen test data', color = 'c')\n",
    "    plt.plot(orig_gps[:, 1], orig_gps[:, 2], label='original gps', color = 'r')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Accuracy of GPS: \", measure_accuracy(ground_truth, orig_gps[:, 1:3]))\n",
    "    print(\"Accuracy of RNN: \", measure_accuracy(ground_truth, predicted_output))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if(print_outputs):\n",
    "\n",
    "#     if(False):\n",
    "#         training_frame = pd.DataFrame(np.concatenate((training_data, training_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y', \n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     else:\n",
    "#         training_frame = pd.DataFrame(np.concatenate((training_data, training_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y',\n",
    "#     #                                                           'Vel X', 'Vel Y',\n",
    "#     #                                                           'Mag X', 'Mag Y',\n",
    "#     #                                                           'Gyro X', 'Gyro Y', 'Gyro Z',\n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     print(\"Training Data\")\n",
    "#     display(training_frame.head(5))\n",
    "#     training_frame.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(print_outputs):\n",
    "\n",
    "#     if(False):\n",
    "#         test_frame = pd.DataFrame(np.concatenate((test_data, test_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y', \n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     else:\n",
    "#         test_frame = pd.DataFrame(np.concatenate((test_data, test_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y',\n",
    "#     #                                                           'Vel X', 'Vel Y',\n",
    "#     #                                                           'Mag X', 'Mag Y',\n",
    "#     #                                                           'Gyro X', 'Gyro Y', 'Gyro Z',\n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     print(\"Testing Data\")\n",
    "#     display(test_frame.head(5))\n",
    "#     # test_frame.plot(figsize=(20,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
