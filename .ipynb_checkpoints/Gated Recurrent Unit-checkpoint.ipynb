{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "import math\n",
    "import sys\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "import numba\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display, HTML\n",
    "%run GRUSupportFns.ipynb\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K \n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.keras.initializers import RandomUniform\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load DataStream and Ground Truth\n",
    "As no reliable ground truth currently, using Kalman Filter results. Note: Ground truth must currently have the same timesteps as the input.\n",
    "\n",
    "https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/23_Time-Series-Prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsed File\n",
      "Freq. of Acceleration 1583.554443181799\n",
      "Freq. of Lin. Acceleration 669.8833983859098\n",
      "Freq. of Gyroscope 1585.3892195648934\n",
      "Interpolated Samples\n",
      "Loaded Ground Truth\n",
      "Rotated Acceleration\n",
      "Integrated Acceleration\n"
     ]
    }
   ],
   "source": [
    "training_data, training_labels, test_data, test_labels,_ = load_train_test_data('uni.csv', 0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_training_data, norm_training_labels, norm_test_data, norm_test_labels = scale_data(training_data, training_labels, \n",
    "                                                                                        test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(norm_test_data, axis=0), \n",
    "                   np.expand_dims(norm_test_labels, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Tensorflow Session \n",
    "\n",
    "Batches in the shape (Batch Size, Sequence Length, Input Dimension)\n",
    "\n",
    "Hyper-parameters:\n",
    " - Batch Size\n",
    " - Sequence Length\n",
    " - Number of States in GRU layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "generator = batch_generator(batch_size=512, sequence_length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(units=1024, return_sequences=True, input_shape=(None, x_dim,), activation = 'linear'))\n",
    "model.add(GRU(units=1024, return_sequences=True, activation = 'linear'))\n",
    "model.add(Dense(y_dim, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, None, 1024)        3164160   \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 1024)        6294528   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 2)           2050      \n",
      "=================================================================\n",
      "Total params: 9,460,738\n",
      "Trainable params: 9,460,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# optimizer = tf.train.RMSPropOptimizer(learning_rate=1e-3)\n",
    "optimizer = RMSprop(lr=1e-3)\n",
    "model.compile(loss=custom_loss, optimizer=optimizer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_checkpoint = '23_checkpoint.keras'\n",
    "# callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "#                                       monitor='val_loss',\n",
    "#                                       verbose=1,\n",
    "#                                       save_weights_only=True,\n",
    "#                                       save_best_only=True)\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=3, verbose=1)\n",
    "# callback_tensorboard = TensorBoard(log_dir='./23_logs/',\n",
    "#                                    histogram_freq=0,\n",
    "#                                    write_graph=False)\n",
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-5,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)       \n",
    "plot_losses = PlotLosses()\n",
    "\n",
    "callbacks = [callback_early_stopping,\n",
    "#              callback_checkpoint,\n",
    "#              callback_tensorboard,\n",
    "             plot_losses,\n",
    "             callback_reduce_lr]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    " - Choose the maximum amount of epochs\n",
    " - How many batches of the data per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      " 91/100 [==========================>...] - ETA: 6s - loss: 55.3734"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# model.fit(np.expand_dims(scaled_training_data, axis=0), np.expand_dims(scaled_training_labels, axis=0), epochs=10, \n",
    "#           batch_size=32, validation_data=validation_data, callbacks=callbacks)\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=30,\n",
    "                    steps_per_epoch=100, #Number of batches per epoch\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(norm_test_data, axis=0),\n",
    "                        y=np.expand_dims(norm_test_labels, axis=0))\n",
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_comparison('data5.csv', train_percentage=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_comparison('uni.csv', train_percentage=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Tensorflow Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.reset_default_graph()\n",
    "# sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
