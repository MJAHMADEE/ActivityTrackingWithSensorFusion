{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import integrate\n",
    "from scipy import interpolate\n",
    "import math\n",
    "import sys\n",
    "from scipy import signal\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from numba import cuda\n",
    "import numba\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import display, HTML\n",
    "%run KalmanFilter.ipynb\n",
    "import mpld3\n",
    "mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.python.keras import backend as K \n",
    "from IPython.display import clear_output\n",
    "from tensorflow.python.keras.initializers import RandomUniform\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dim = 5\n",
    "y_dim = 2\n",
    "def create_input_and_output(data, just_acc=False):\n",
    "    ## Needed Data\n",
    "    gps = data.gps[:, 1:3]\n",
    "    acc = data.acc_ERC[:, 1:3]\n",
    "    vel = data.vel_ERC[:, 1:3]\n",
    "    mag = data.mag[:, 1:3]\n",
    "    gyro = data.gyro[:, 1:4]\n",
    "\n",
    "    time_series = data.acc_ERC[:, 0]\n",
    "#     ground_truth = data.kal_dis[:, 1:3]\n",
    "    ground_truth = data.ground_truth.dis[:, 1:3]\n",
    "    delta_time = np.diff(time_series, axis=0)\n",
    "    delta_time = np.concatenate(([[0]], delta_time))\n",
    "\n",
    "    # Choose which data to include in input\n",
    "    if (just_acc):\n",
    "        input_data = np.concatenate((gps, acc, delta_time), axis=1)\n",
    "    else:\n",
    "        input_data = np.concatenate((gps, acc, delta_time), axis=1)\n",
    "    return input_data, ground_truth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_test_data(filename, train_percentage=0.8):\n",
    "    #Load Data File\n",
    "    data = Data_Stream(filename, load_truth=True)\n",
    "    \n",
    "    #Create input and ouput data\n",
    "    input_data, ground_truth = create_input_and_output(data)\n",
    "    \n",
    "    x_dim = input_data.shape[1]\n",
    "    y_dim = ground_truth.shape[1]\n",
    "\n",
    "    num_train = int(train_percentage*len(input_data))\n",
    "    num_test = len(input_data) - num_train\n",
    "\n",
    "    training_data   = input_data[:num_train, :]\n",
    "    training_labels = ground_truth[:num_train, :]\n",
    "\n",
    "    test_data     = input_data[num_train:, :]\n",
    "    test_labels   = ground_truth[num_train:, :]\n",
    "    \n",
    "    return training_data, training_labels, test_data, test_labels, data.gps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_scale_matrix = np.zeros((2, x_dim))\n",
    "custom_scale_matrix.fill(2000)\n",
    "custom_scale_matrix[1, :] = -custom_scale_matrix[1 , :]\n",
    "\n",
    "x_scaler = MinMaxScaler()\n",
    "x_scaler = x_scaler.fit(custom_scale_matrix)\n",
    "y_scaler = MinMaxScaler()\n",
    "y_scaler = y_scaler.fit(custom_scale_matrix[:, 0:2])\n",
    "\n",
    "def scale_data(training_data, training_labels, test_data, test_labels):\n",
    "\n",
    "    norm_training_data = x_scaler.transform(training_data)\n",
    "    norm_test_data = x_scaler.transform(test_data)\n",
    "    norm_training_labels = y_scaler.transform(training_labels)\n",
    "    norm_test_labels = y_scaler.transform(test_labels)\n",
    "    \n",
    "    \n",
    "    return norm_training_data, norm_training_labels, norm_test_data, norm_test_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    while True:\n",
    "        x_shape = (batch_size, sequence_length, x_dim)\n",
    "        x_batch = np.zeros(shape=x_shape, dtype=np.float16)\n",
    "\n",
    "        y_shape = (batch_size, sequence_length, y_dim)\n",
    "        y_batch = np.zeros(shape=y_shape, dtype=np.float16)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            rand_start = np.random.randint(len(norm_training_data) - sequence_length)\n",
    "            \n",
    "            x_batch[i] = norm_training_data[rand_start : rand_start + sequence_length]\n",
    "            y_batch[i] = norm_training_labels[rand_start : rand_start + sequence_length]\n",
    "            \n",
    "        yield (x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    \n",
    "    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "    \n",
    "    \n",
    "#     ts = tf.reshape(y_true_slice, (-1, 2))\n",
    "    \n",
    "#     ps = tf.reshape(y_pred_slice, (-1, 2))\n",
    "    \n",
    "#     def get_min_dist(pi):\n",
    "# #         print(pi.get_shape(), ts.get_shape())\n",
    "#         eu_dists = tf.norm(ts-pi, ord='euclidean', axis=1)\n",
    "#         min_dist = tf.reduce_min(eu_dists)\n",
    "#         return min_dist\n",
    "\n",
    "\n",
    "#     min_dists = tf.map_fn(get_min_dist, ps, dtype=tf.float32)\n",
    "#     print(\"Minimum distances to Ground Truth Points Shape\", min_dists.get_shape())\n",
    "#     mean_dist = tf.reduce_mean(min_dists)\n",
    "#     print(\"Mean Mimimum Distance Shape\", mean_dist.get_shape())\n",
    "    \n",
    "# #     min_dists_tot = 0.0\n",
    "# #     print(ps.shape)\n",
    "# #     for pi in ps:\n",
    "# #         min_t = sys.float_info.max\n",
    "# #         for ti in ts:\n",
    "# #             t = tf.norm(ti-pi, ord='euclidean')\n",
    "# #             if(t < min_t):\n",
    "# #                 min_t = t\n",
    "# #         min_dists_tot += min_t\n",
    "        \n",
    "# #     mean_dist = min_dists_tot/len(ps)\n",
    "    \n",
    "    eu_dists = tf.norm(y_true_slice-y_pred_slice, ord='euclidean')\n",
    "    loss_mean = tf.reduce_mean(eu_dists)\n",
    "    \n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(tf.keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure(figsize=(20, 10))\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.ioff()\n",
    "        plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(filename, start_index=0, individual_signals=False, train_percentage=0.8):\n",
    "    training_data, training_labels, test_data, test_labels, orig_gps = load_train_test_data(filename, train_percentage)\n",
    "\n",
    "    \n",
    "    trial_input = np.concatenate((training_data, test_data))\n",
    "    ground_truth = np.concatenate((training_labels, test_labels))\n",
    "\n",
    "    ##Scale down the trial input, get predicted output\n",
    "    trial_input = x_scaler.transform(trial_input)\n",
    "    trial_input = np.expand_dims(trial_input, axis=0)\n",
    "    predicted_output = model.predict(trial_input)\n",
    "    \n",
    "    \n",
    "    ## Remove data upto the start point\n",
    "    ground_truth = ground_truth[start_index:]\n",
    "    orig_gps = orig_gps[start_index:]\n",
    "    predicted_output = y_scaler.inverse_transform(predicted_output[0])[start_index:]\n",
    "    \n",
    "\n",
    "    # The output of the model is between 0 and 1. Inverse rescale to get input\n",
    "    if(individual_signals):\n",
    "        for signal in range(ground_truth_output.shape[1]):\n",
    "\n",
    "            # Make the plotting-canvas bigger.\n",
    "            plt.figure(figsize=(8,5))\n",
    "\n",
    "            # Plot and compare the ground truth and Model predicted versions\n",
    "            plt.plot(ground_truth[:, signal],'ro', label='true')\n",
    "            plt.plot(predicted_output[:, signal], label='pred')\n",
    "\n",
    "            # Plot grey box for warmup-period.\n",
    "            p = plt.axvspan(0, warmup_steps, facecolor='red', alpha=0.15)\n",
    "\n",
    "            # Plot labels etc.\n",
    "            plt.ylabel(\"X Displacement\" if signal == 0 else \"Y Displacement\")\n",
    "            plt.xlabel(\"Timestep\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            \n",
    "    ##Print Graphs of X against Y\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(ground_truth[:, 0], ground_truth[:, 1], label='true', color = 'g')\n",
    "    plt.plot(predicted_output[:len(training_data), 0], predicted_output[:len(training_data), 1], \n",
    "             label='predicted training', color = 'b')\n",
    "    plt.plot(predicted_output[len(training_data):, 0], predicted_output[len(training_data):, 1], \n",
    "             label='predicted test', color = 'c')\n",
    "    plt.plot(orig_gps[:, 1], orig_gps[:, 2], label='original gps', color = 'r')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Accuracy of GPS: \", measure_accuracy(ground_truth, orig_gps[:, 1:3]))\n",
    "    print(\"Accuracy of RNN: \", measure_accuracy(ground_truth, predicted_output))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Data with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# if(print_outputs):\n",
    "\n",
    "#     if(False):\n",
    "#         training_frame = pd.DataFrame(np.concatenate((training_data, training_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y', \n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     else:\n",
    "#         training_frame = pd.DataFrame(np.concatenate((training_data, training_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y',\n",
    "#     #                                                           'Vel X', 'Vel Y',\n",
    "#     #                                                           'Mag X', 'Mag Y',\n",
    "#     #                                                           'Gyro X', 'Gyro Y', 'Gyro Z',\n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     print(\"Training Data\")\n",
    "#     display(training_frame.head(5))\n",
    "#     training_frame.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if(print_outputs):\n",
    "\n",
    "#     if(False):\n",
    "#         test_frame = pd.DataFrame(np.concatenate((test_data, test_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y', \n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     else:\n",
    "#         test_frame = pd.DataFrame(np.concatenate((test_data, test_labels), axis=1), \n",
    "#                                                      columns=['GPS X', 'GPS Y', 'Acc X', 'Acc Y',\n",
    "#     #                                                           'Vel X', 'Vel Y',\n",
    "#     #                                                           'Mag X', 'Mag Y',\n",
    "#     #                                                           'Gyro X', 'Gyro Y', 'Gyro Z',\n",
    "#                                                               'Delta Time', 'Ground Truth X', 'Ground_Truth Y'])\n",
    "#     print(\"Testing Data\")\n",
    "#     display(test_frame.head(5))\n",
    "#     # test_frame.plot(figsize=(20,10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
